from argparse import ArgumentParser
from collections import namedtuple
from lxml import etree
import csv
import pathlib

# declare all the named tuples up front
JATS = namedtuple('JATS', 'id doi issn journal volume issue year referenceCount title authors')

def extract_metadata(folder_in, file_out):
    folder_in = pathlib.Path(folder_in)
    file_out = pathlib.Path(file_out)
    ensure_path(file_out)

    for file_name in folder_in.iterdir():
        if file_name.is_file() and file_name.suffix.lower() == '.json':



def ensure_path(file_out):
    file_out.parent.mkdir(parents = True, exist_ok = True)
    if file_out.exists():
         file_out.unlink()

def extract_metadata(merged_tarball):
    """
    Converts an OAS dump file to tar ball containing all the articles minus any JATS markup.
    There can be more articles in the metadata file than in the file generated by `convert_oas_dump_to_text()`.
    This is because `convert_oas_dump_to_text()` removes some of the nonsence articles.
    If you want an exact match, do an inner join

    Parameters
    ----------
    merged_tarball : str
        The merged TAR dump file from PMC
    """
    
    merged_tarball = pathlib.Path(merged_tarball)

    metadata = merged_tarball.parent.joinpath('./metadata.csv')    
    if metadata.exists():
        metadata.unlink()

    print('Extracting Metadata')
    meta_hash = set()

    with open(metadata, 'w', encoding = 'utf-8', newline = '') as metadata:
        metadata = csv.writer(metadata, delimiter = ',', quotechar = '"', quoting = csv.QUOTE_ALL)    
        metadata.writerow(['id', 'doi', 'issn', 'journal', 'volume', 'issue', 'year', 'referenceCount', 'title', 'authors'])
        for (tar_info, tar_file) in file_in_corpus(merged_tarball):
            try:
                jats = parse_jats(tar_file.read())
                if jats.id not in meta_hash:
                    metadata.writerow([jats.id, jats.doi, jats.issn, jats.journal, jats.volume, jats.issue, jats.year, jats.referenceCount, jats.title, jats.authors])
                    meta_hash.add(jats.id)
                pass
            except Exception as ex:
                print(tar_info.name + ': ' + str(ex))
                pass
            pass
    
    return metadata

def parse_jats(xml):
    """
    Gets the parts of the JATS XML we care about
    """

    journal = "./front/journal-meta//journal-title"
    volume = "./front/article-meta/volume"
    issue = "./front/article-meta/issue"
    id = "./front/article-meta/article-id[@pub-id-type='pmc']"
    doi = "./front/article-meta/article-id[@pub-id-type='doi']"
    issn = './front/journal-meta/issn'
    year = "./front/article-meta/pub-date/year/text()"
    references = "./back/ref-list/ref"
    title = "./front/article-meta/title-group/article-title//text()"
    authors = "./front/article-meta/contrib-group/contrib/name"    

    root = etree.fromstring(xml)

    journal = nct(root.find(journal))
    volume = nct(root.find(volume))
    issue = nct(root.find(issue))
    id = nct(root.find(id))
    doi = nct(root.find(doi))
    issn = ';'.join(map(nct, root.xpath(issn)))
    year = min(map(lambda year: int(year) , root.xpath(year)))
    references = root.findall(references)
    title = ' '.join(''.join(root.xpath(title)).split())
    authors = ';'.join(map(extract_author_name, root.xpath(authors)))

    return JATS(id.rjust(10, '0'), doi, issn, journal, volume, issue, year, len(references), title, authors)

def nct(obj):
    """
    Simple null-conditional macro
    """

    if obj is None:
        return None
    elif obj.text is None:
        return None
    else:
        return obj.text.strip()

def extract_author_name(node):
    """
    gets the author name in the expected format
    """
    given = node.xpath("./given-names/text()")
    sur = node.xpath("./surname/text()")

    given = next(iter(given or []), '')
    sur = next(iter(sur or []), '')

    full = '{given} {sur}'.format(given = given, sur = sur).strip()
    
    return full if len(full) > 3 else '???'

if __name__ == '__main__':
    #parser = ArgumentParser()
    #parser.add_argument('-in', '--folder-in', help = 'Folder containing the raw JSON files', required = True)
    #parser.add_argument('-out', '--file-out', help = 'File to contain the metadata', required = True)
    #args = parser.parse_args()
    #print(f'folder in: {args.folder_in}')
    #print(f'file out: {args.file_out}')
    #extract_metadata(args.folder_in, args.file_out)
    extract_metadata('d:/oas', 'd:/oas/metadata.csv')
